{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6e32f74f",
      "metadata": {
        "id": "6e32f74f"
      },
      "source": [
        "# Lab 4 - LDPC Factor Graph Construction\n",
        "\n",
        "This is the first of the two colab notebooks that form the project.\n",
        "\n",
        "Here you will construct a **factor graph** for decoding a (regular)\n",
        "**low-density parity-check (LDPC)** code. Although communication systems often\n",
        "refer to messages and codewords, in this lab we model only the transmitted bits\n",
        "$x$ and the channel outputs $y$. All other steps are either preprocessing\n",
        "(encoding) or postprocessing (reading off the decoded bits).\n",
        "\n",
        "As the block length $N$ increases, well-designed LDPC codes achieve better decoding performance, while the treewidth of the factor graph grows, making exact inference intractable and motivating approximate methods such as belief propagation.\n",
        "\n",
        "\n",
        "## Learning goals\n",
        "\n",
        "- Represent an LDPC code as a **factor graph** with:\n",
        "  - binary **variable nodes** (bits),\n",
        "  - **parity-check factors** (XOR constraints),\n",
        "  - **channel factors** connecting each transmitted bit to its channel output.\n",
        "- Validate the graph:\n",
        "  - **structurally**: degrees, factor arities, correct wiring,\n",
        "  - **semantically**: parity-check factors behave correctly on a known satisfying assignment.\n",
        "\n",
        "You will be given:\n",
        "- a generator for a *regular* parity-check matrix $H$ (with configurable density),\n",
        "- a Binary Symmetric Channel (BSC) noise generator.\n",
        "\n",
        "You will implement:\n",
        "1. a parity-check factor constructor,\n",
        "2. a channel factor constructor,\n",
        "3. the factor-graph construction from $H$,\n",
        "4. graph validation checks and visualization,\n",
        "5. treewidth scaling analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee5d32e",
      "metadata": {
        "id": "1ee5d32e"
      },
      "outputs": [],
      "source": [
        "# Colab setup\n",
        "!pip -q install pgmpy networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bf3542d",
      "metadata": {
        "id": "9bf3542d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import networkx as nx\n",
        "\n",
        "from pgmpy.models import FactorGraph\n",
        "from pgmpy.factors.discrete import DiscreteFactor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kZXxCGwjkfMe",
      "metadata": {
        "id": "kZXxCGwjkfMe"
      },
      "source": [
        "# Factor graphs for Low-Density Parity-Check (LDPC) decoding\n",
        "\n",
        "## Variables and factorization\n",
        "\n",
        "The task is to transmit $N$ bits over a noisy channel. LDPC codes introduce $M$\n",
        "parity-check constraints to enable error correction.\n",
        "\n",
        "The factor graph contains two types of binary variables:\n",
        "- **transmitted bits**: $x_0,\\dots,x_{N-1}$\n",
        "- **channel outputs**: $y_0,\\dots,y_{N-1}$\n",
        "\n",
        "The joint distribution defined by the factor graph factorizes as\n",
        "$$\n",
        "p(x,y)\n",
        "\\;\\propto\\;\n",
        "\\prod_{m=1}^M \\psi_m\\bigl(x_{N(m)}\\bigr)\n",
        "\\;\\;\n",
        "\\prod_{n=0}^{N-1} \\phi_n(x_n, y_n),\n",
        "$$\n",
        "\n",
        "where $N(m)$ denotes the set of transmitted-bit indices that appear in factor\n",
        "$\\psi_m$, and:\n",
        "- $\\psi_m$ are **parity-check factors** enforcing local constraints on transmitted bits,\n",
        "- $\\phi_n$ are **channel factors** modeling the noise affecting each bit.\n",
        "\n",
        "## Parity-check factors $\\psi_m(x_{N(m)})$\n",
        "\n",
        "Each parity-check factor enforces an even-parity constraint on a small subset of\n",
        "transmitted bits.\n",
        "\n",
        "Formally, the factor is defined as\n",
        "$$\n",
        "\\psi_m\\bigl(x_{N(m)}\\bigr)\n",
        "\\;=\\;\n",
        "\\begin{cases}\n",
        "1 & \\text{if } \\sum_{n \\in N(m)} x_n \\equiv 0 \\pmod 2, \\\\\n",
        "0 & \\text{otherwise}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Thus, each parity-check factor is a **local constraint** that involves only the\n",
        "$k$ transmitted-bit variables connected to it.\n",
        "\n",
        "## Channel factors $\\phi_n(x_n,y_n)$\n",
        "\n",
        "Each channel factor connects a transmitted bit $x_n$ to its corresponding channel\n",
        "output $y_n$.\n",
        "\n",
        "We model the channel as a **binary symmetric channel (BSC)** with flip probability\n",
        "$f$, defining\n",
        "$$\n",
        "\\phi_n(x_n,y_n)\n",
        "=\n",
        "p(y_n \\mid x_n)\n",
        "=\n",
        "\\begin{cases}\n",
        "1-f & \\text{if } y_n = x_n, \\\\\n",
        "f   & \\text{if } y_n \\neq x_n.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Channel factors are independent across bit positions.\n",
        "\n",
        "## Decoding as inference\n",
        "\n",
        "In a communication scenario, the channel outputs\n",
        "$y_0,\\dots,y_{N-1}$ are observed.\n",
        "\n",
        "Decoding consists of inferring the transmitted bits\n",
        "$x_0,\\dots,x_{N-1}$ given these observations, that is, computing the posterior\n",
        "distribution $p(x \\mid y)$.\n",
        "\n",
        "In the next session, you will approximate this posterior using belief propagation on the same factor graph, after introducing evidence on the $y$ variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56712358",
      "metadata": {
        "id": "56712358"
      },
      "source": [
        "## Regular LDPC parity-check matrix generator\n",
        "\n",
        "A **regular LDPC code** is specified by a sparse parity-check matrix $H \\in \\{0,1\\}^{M \\times N},$which defines the structure of the parity-check factors in the factor graph.\n",
        "\n",
        "- Each row corresponds to one parity-check factor.\n",
        "- Each column corresponds to one transmitted-bit variable.\n",
        "- Each row has exactly $k$ ones (each check involves $k$ bits).\n",
        "- Each column has exactly $j$ ones (each bit participates in $j$ checks).\n",
        "\n",
        "For a given row $m$, the set\n",
        "$$\n",
        "N(m) = \\{\\, n : H_{m,n} = 1 \\,\\}\n",
        "$$\n",
        "is exactly the set of transmitted bits connected to parity-check factor $\\psi_m$.\n",
        "\n",
        "The following code generates a random **regular LDPC** parity-check matrix:\n",
        "- each **column** has weight $j$,\n",
        "- each **row** has weight $k$.\n",
        "\n",
        "If generation fails (rare for small sizes), re-run the cell or adjust the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1592b03",
      "metadata": {
        "id": "b1592b03"
      },
      "outputs": [],
      "source": [
        "def generate_regular_ldpc_H(N: int, j: int, k: int, seed: int = 0, max_tries: int = 2000) -> np.ndarray:\n",
        "    \"\"\"Generate a random (j,k)-regular binary parity-check matrix H of shape (M,N),\n",
        "    where M = N*j/k must be an integer.\n",
        "\n",
        "    Notes:\n",
        "    - This construction is intentionally simple (sufficient for the lab).\n",
        "    - It may create short cycles; that's fine (Lab 2 is loopy).\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    if (N * j) % k != 0:\n",
        "        raise ValueError(f\"Need M = N*j/k integer, but N*j={N*j} not divisible by k={k}.\")\n",
        "    M = (N * j) // k\n",
        "\n",
        "    for _ in range(max_tries):\n",
        "        # Create j \"stubs\" per column\n",
        "        col_stubs = np.repeat(np.arange(N), j)\n",
        "        rng.shuffle(col_stubs)\n",
        "\n",
        "        # Assign stubs into M groups of size k (rows)\n",
        "        H = np.zeros((M, N), dtype=np.uint8)\n",
        "        ok = True\n",
        "        for m in range(M):\n",
        "            cols = col_stubs[m * k : (m + 1) * k]\n",
        "            # avoid duplicate variable in a single check (keeps row weight exactly k)\n",
        "            if len(set(cols.tolist())) != k:\n",
        "                ok = False\n",
        "                break\n",
        "            H[m, cols] = 1\n",
        "        if not ok:\n",
        "            continue\n",
        "\n",
        "        # Verify regularity\n",
        "        if np.all(H.sum(axis=0) == j) and np.all(H.sum(axis=1) == k):\n",
        "            return H\n",
        "\n",
        "    raise RuntimeError(\"Failed to construct a regular LDPC matrix. Try a different seed or parameters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37bd9f68",
      "metadata": {
        "id": "37bd9f68"
      },
      "source": [
        "## Part 1: Choose code parameters and generate $H$\n",
        "\n",
        "Pick modest sizes so you can visualize and test easily.\n",
        "Suggested starting point:\n",
        "- $N=24$, $j=3$, $k=6$  (then $M=\\frac{N j}{k} = 12$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3352197a",
      "metadata": {
        "id": "3352197a"
      },
      "outputs": [],
      "source": [
        "# TODO: Choose parameters\n",
        "N = 24\n",
        "j = 3\n",
        "k = 6\n",
        "seed_H = 0\n",
        "\n",
        "H = generate_regular_ldpc_H(N=N, j=j, k=k, seed=seed_H)\n",
        "M = H.shape[0]\n",
        "print(H)\n",
        "\n",
        "print(\"H shape:\", H.shape)\n",
        "print(\"column weights (should all be j):\", np.unique(H.sum(axis=0)))\n",
        "print(\"row weights (should all be k):\", np.unique(H.sum(axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5b83422",
      "metadata": {
        "id": "d5b83422"
      },
      "source": [
        "## Part 2: Build factors\n",
        "\n",
        "### 2.1 Parity-check factors $\\psi_m(x_{N(m)})$\n",
        "\n",
        "Implement `make_parity_check_factor` which receives a matrix $H$, a set of variables, and returns a factor defined over the transmitted-bit variables connected to that row.\n",
        "\n",
        "It should be:\n",
        "- value = 1 if the parity constraint is satisfied (even parity)\n",
        "- value = 0 otherwise\n",
        "\n",
        "Tips:\n",
        "- With `DiscreteFactor`, you provide a `values` array of length $2^d$ (reshaped to `[2]*d`),\n",
        "  where `d` is the number of variables in that factor.\n",
        "- You can generate all assignments with `itertools.product([0,1], repeat=d)`.\n",
        "\n",
        "<center>\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>$x_1$</th>\n",
        "      <th>$x_2$</th>\n",
        "      <th>$x_3$</th>\n",
        "      <th>$\\psi_{{123}}$</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
        "    <tr><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
        "    <tr><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
        "    <tr><td>0</td><td>1</td><td>1</td><td>1</td></tr>\n",
        "    <tr><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "    <tr><td>1</td><td>0</td><td>1</td><td>1</td></tr>\n",
        "    <tr><td>1</td><td>1</td><td>0</td><td>1</td></tr>\n",
        "    <tr><td>1</td><td>1</td><td>1</td><td>0</td></tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<br>Example of a 3-wise parity-check factor\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1456b3cc",
      "metadata": {
        "id": "1456b3cc"
      },
      "outputs": [],
      "source": [
        "def make_parity_check_factor(var_names):\n",
        "    \"\"\"Return a DiscreteFactor enforcing even parity over var_names.\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce68fda",
      "metadata": {
        "id": "cce68fda"
      },
      "source": [
        "## Channel factors $\\phi_n(x_n,y_n)$\n",
        "\n",
        "Implement `make_bsc_channel_factor(x_var, y_var, f)`,\n",
        "a **pairwise factor** over `(x_var, y_var)` defined by a **binary symmetric channel (BSC)** with flip probability $f$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "968a13c2",
      "metadata": {
        "id": "968a13c2"
      },
      "outputs": [],
      "source": [
        "def make_bsc_channel_factor(x_var, y_var, f):\n",
        "    \"\"\"Pairwise channel factor for a BSC.\n",
        "    Returns a DiscreteFactor over [x_var, y_var] with cardinalities [2,2].\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d2c54f",
      "metadata": {
        "id": "05d2c54f"
      },
      "source": [
        "## Part 3: Create the factor graph from $H$\n",
        "\n",
        "Construct a `pgmpy` `FactorGraph`:\n",
        "\n",
        "1. add variable nodes: `x0...x{N-1}`\n",
        "2. add parity-check factors (one per row of H) and connect them\n",
        "3. (optional today, required later) add likelihood factors and connect them\n",
        "\n",
        "Implement:\n",
        "- `build_ldpc_factor_graph(H, y=None, f=None)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d51077",
      "metadata": {
        "id": "93d51077"
      },
      "outputs": [],
      "source": [
        "def build_ldpc_factor_graph(H: np.ndarray, f: float) -> FactorGraph:\n",
        "    \"\"\"Build an LDPC factor graph with explicit channel-output variables.\n",
        "\n",
        "    Variables:\n",
        "      - transmitted bits: x0..x{N-1}\n",
        "      - channel outputs:  y0..y{N-1}\n",
        "\n",
        "    Factors:\n",
        "      - parity-check factors on x's (from H)\n",
        "      - channel factors φ_n(x_n, y_n) = p(y_n | x_n) for BSC flip prob f\n",
        "\n",
        "    Evidence (a particular received word Y) will be introduced later by clamping y's.\n",
        "    \"\"\"\n",
        "    M, N = H.shape\n",
        "    x_vars = [f\"x{n}\" for n in range(N)]\n",
        "    y_vars = [f\"y{n}\" for n in range(N)]\n",
        "\n",
        "    G = FactorGraph()\n",
        "\n",
        "    # 1) Add variable nodes\n",
        "\n",
        "    # 2) Add parity-check factors (one per row of H) and connect them\n",
        "\n",
        "    # 3) Add channel factors φ_n(x_n, y_n) and connect them\n",
        "\n",
        "    return G"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chuIFT-lC8mV",
      "metadata": {
        "id": "chuIFT-lC8mV"
      },
      "source": [
        "## Part 4: Validating the factor graph\n",
        "\n",
        "We must verify that the factor graph correctly represents the intended LDPC model.\n",
        "\n",
        "Your task in this part is to **think about validations that make\n",
        "sense**, and to implement some of them.\n",
        "\n",
        "Examples of questions you may consider include:\n",
        "### Structural checks:\n",
        "\n",
        "- Does the number and type of factors match the specification of the LDPC code?\n",
        "- Are parity-check factors connected to the correct subsets of transmitted bits?\n",
        "- Do variable nodes have the expected degrees (for a regular code)?\n",
        "- Do parity-check factors behave correctly on a known satisfying assignment?\n",
        "### Semantic checks:\n",
        "For small $N$, you can test the parity-check factors exhaustively.\n",
        "\n",
        "For each assignment $x \\in \\{0,1\\}^N$ (there are $2^N$ of them), compute the so-called *syndrome*\n",
        "$$\n",
        "s = Hx \\pmod 2.\n",
        "$$\n",
        "The parity-check constraints are satisfied if and only if $s=0$, so the product of\n",
        "all parity-check factors should evaluate to\n",
        "$$\n",
        "\\prod_{m=1}^M \\psi_m(x_{N(m)}) =\n",
        "\\begin{cases}\n",
        "1 & \\text{if } Hx \\equiv 0 \\pmod 2,\\\\\n",
        "0 & \\text{otherwise.}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "For this semantic test you can ignore the $y$ variables and the channel factors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iieAgyh1DIKo",
      "metadata": {
        "id": "iieAgyh1DIKo"
      },
      "outputs": [],
      "source": [
        "def validate_ldpc_graph(G):\n",
        "    \"\"\"Basic validation of an LDPC factor graph.\n",
        "\n",
        "    This function performs a minimal sanity check using G.check_code().\n",
        "    Students are encouraged to extend it with additional structural or\n",
        "    semantic validations.\n",
        "    \"\"\"\n",
        "    assert G.check_model(), \"Basic LDPC graph validation failed.\"\n",
        "\n",
        "    # TODO:\n",
        "    # Add additional checks, for example:\n",
        "    # - number of variable and factor nodes\n",
        "    # - degrees of x and y variables\n",
        "    # - parity-check factor arities\n",
        "    # - behavior of parity-check factors on a known satisfying assignment\n",
        "    # ...\n",
        "\n",
        "    return True\n",
        "\n",
        "N = 24\n",
        "j = 3\n",
        "k = 6\n",
        "seed_H = 0\n",
        "H = generate_regular_ldpc_H(N=N, j=j, k=k, seed=seed_H)\n",
        "G = build_ldpc_factor_graph(H, f=0.8)\n",
        "validate_ldpc_graph(G, H, 10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59a1eb83",
      "metadata": {
        "id": "59a1eb83"
      },
      "source": [
        "## Part 5: Visualization\n",
        "\n",
        "Implement code that visualizes a factor graph.\n",
        "\n",
        "You can use `networkx` and `matplotlib.pyplot`, and all the functions from that library such as `nx.draw_networkx_nodes`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c11a487",
      "metadata": {
        "id": "6c11a487"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from pgmpy.models import FactorGraph\n",
        "\n",
        "def visualize_factor_graph(G: FactorGraph, max_nodes: int = 200):\n",
        "    \"\"\"Visualize an LDPC factor graph with a fixed column layout.\n",
        "\n",
        "    Columns (left to right):\n",
        "      y variables → channel factors → x variables → parity-check factors\n",
        "    \"\"\"\n",
        "    Hnx = nx.Graph()\n",
        "\n",
        "    # TODO:\n",
        "    # visualize the graph\n",
        "\n",
        "\n",
        "H = generate_regular_ldpc_H(N=24, j=3, k=6, seed=1)\n",
        "G = build_ldpc_factor_graph(H, f=0.8)\n",
        "visualize_factor_graph(G)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dKoOHfg8esDk",
      "metadata": {
        "id": "dKoOHfg8esDk"
      },
      "source": [
        "## Part 6: Treewidth scaling with block length $N$\n",
        "\n",
        "To study how inference complexity scales with the block length $N$, we analyze the **treewidth** of the LDPC code.\n",
        "\n",
        "We first construct the **primal graph** on the transmitted bits $x_0,\\dots,x_{N-1}$: this is an undirected graph in which two bits are connected by an edge if they appear together in any parity-check factor. It is analogous to moralization, but applied to a factor graph rather than a Bayesian network.\n",
        "\n",
        "Since computing treewidth exactly is NP-hard, we estimate it using a\n",
        "**min-fill heuristic**, which provides an upper bound on the treewidth.\n",
        "\n",
        "Use `networkx.algorithms.approximation.treewidth_min_fill_in` to estimate the\n",
        "treewidth of the primal graph for increasing values of $N$, and plot the result. When do you think inference will start being intractable?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K5b_8CphbLU4",
      "metadata": {
        "id": "K5b_8CphbLU4"
      },
      "outputs": [],
      "source": [
        "from networkx.algorithms.approximation import treewidth_min_fill_in\n",
        "\n",
        "def ldpc_primal_graph_on_x(G):\n",
        "    \"\"\"Build the primal graph on x-variables only.\n",
        "\n",
        "    Nodes: x0..x{N-1}\n",
        "    Edge between xi and xj if some parity-check factor contains both.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    # - create an undirected NetworkX graph\n",
        "    # - add one node per x-variable\n",
        "    # - for each parity-check factor, connect all x-variables that appear together\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def treewidth_scaling_experiment(N_list, j, k, f=0.08, seed0=0):\n",
        "    \"\"\"Estimate treewidth scaling for increasing block lengths N.\n",
        "\n",
        "    Returns a list of tuples (N, estimated_treewidth, num_edges).\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    # - for each N:\n",
        "    #   - generate a regular LDPC parity-check matrix H\n",
        "    #   - build the LDPC factor graph\n",
        "    #   - construct the primal graph on x-variables\n",
        "    #   - estimate treewidth using networkx.treewidth_min_fill_in\n",
        "    # - return the collected results\n",
        "    raise NotImplementedError\n",
        "\n",
        "N_list = [12, 18, 24, 30, 36, 42, 50]\n",
        "j, k = 3, 6\n",
        "tw_results = treewidth_scaling_experiment(N_list, j=j, k=k, f=0.08, seed0=0)\n",
        "tw_results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
